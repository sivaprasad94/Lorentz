{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ESN\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=42):\n",
    "    \"\"\"Making the seed (for random values) variable if None\"\"\"\n",
    "    # Set the seed\n",
    "    if seed is None:\n",
    "        import time\n",
    "        seed = int((time.time()*10**6) % 4294967295)\n",
    "    try:\n",
    "        np.random.seed(seed)\n",
    "    except Exception as e:\n",
    "        print( \"!!! WARNING !!!: Seed was not set correctly.\")\n",
    "        print( \"!!! Seed that we tried to use: \"+str(seed))\n",
    "        print( \"!!! Error message: \"+str(e))\n",
    "        seed = None\n",
    "    print( \"Seed used for random values:\", seed)\n",
    "    return seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_excel(r'C:\\Users\\INFO-DSK-02\\Desktop\\Lorentz Multi Dimension Prediction-Phase-2\\Final_Version\\3D_ReservoirComputing\\Input\\Lorentz data testing and training.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "initLen = 50 \n",
    "trainLen = initLen + 1950\n",
    "testLen = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in = df[['x','y','z']]\n",
    "data_T  =df['t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in = np.array(data_in)\n",
    "data_t = np.array(data_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in = np.array(data_in[0:trainLen])\n",
    "train_out = np.array(data_in[0+10:trainLen+10])\n",
    "valid_in = np.array(data_in[trainLen:trainLen+testLen])\n",
    "valid_out = np.array(data_in[trainLen+10:trainLen+testLen+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_r = [300,400,500,800] # number of recurrent units\n",
    "l_r =[0.3,0.2,0.1,0.4] # leaking rate (=1/time_constant_of_neurons)\n",
    "s_r = [1,1.2,1.4,1.5]\n",
    "r_c = [1e-3,1e-2,1e-1,1e-4]\n",
    "train_in = train_in\n",
    "train_out = train_out\n",
    "valid_in = valid_in\n",
    "valid_out = valid_out\n",
    "input_bias = True\n",
    "dim_inp = 3\n",
    "n_outputs = 3\n",
    "initLen = initLen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = []\n",
    "for i in n_r:\n",
    "    for j in l_r:\n",
    "        for k in s_r:\n",
    "            for l in r_c:\n",
    "                combinations.append([i,j,k,l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yield successive n-sized \n",
    "# chunks from l. \n",
    "def divide_chunks(l, n): \n",
    "      \n",
    "    # looping till length l \n",
    "    for i in range(0, len(l), n):  \n",
    "        yield l[i:i + n] \n",
    "  \n",
    "# How many elements each \n",
    "# list should have \n",
    "n = 4\n",
    "  \n",
    "x = list(divide_chunks(combinations, n)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in x:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[i][25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "grids = numpy.vectorize(ESN_TUNE)(*numpy.ix_(n_r,l_r,s_r,r_c))\n",
    "max_grid = grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_reservoir = 300\n",
    "leak_rate = 0\n",
    "spectral_radius = 1.4\n",
    "regularization_coef = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152.92673580000337\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import threading\n",
    "import time\n",
    "t1 = time.perf_counter()\n",
    "if __name__ == '__main__':\n",
    "    # create and start our threads\n",
    "    threads = list()\n",
    "    \n",
    "    n_reservoir = 300\n",
    "    leak_rate = 0\n",
    "    spectral_radius = 1.4\n",
    "    regularization_coef = 1e-3\n",
    "    for j in range(len(x)):\n",
    "        n = len(x[j])\n",
    "        for i in range(n):\n",
    "            t = threading.Thread(target=ESN_TUNE, args = (x[j][i][0], x[j][i][1], x[j][i][2], x[j][i][3])) # pass in the callable\n",
    "            threads.append(t)\n",
    "#             print('Starting Thread {}'.format(i))\n",
    "            t.start()\n",
    "        for i, t in enumerate(threads):\n",
    "            t.join()\n",
    "        for t in threads:\n",
    "            if t.isAlive() == True:\n",
    "                t.kill()\n",
    "\n",
    "#     # wait for each to finish (join)\n",
    "#     for i, t in enumerate(threads):\n",
    "#         t.join()\n",
    "#         print('Thread {} Stopped'.format(i))\n",
    "t2 = time.perf_counter()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ESN_TUNE(n_reservoir, leak_rate, regularization_coef, spectral_radius):\n",
    "    Best_Parameters = []\n",
    "    input_bias = True\n",
    "    nr = n_reservoir\n",
    "    L = leak_rate\n",
    "    R = regularization_coef\n",
    "    s_r = spectral_radius\n",
    "    dim_inp = 3\n",
    "    n_outputs = 3\n",
    "    dim_inp = 3\n",
    "    initLen = 100\n",
    "    parameters = []\n",
    "    N =  n_reservoir#100\n",
    "    spectral_radius = s_r\n",
    "    input_scaling = 1. # Scaling of input matrix\n",
    "    proba_non_zero_connec_W = 0.2 # Sparsity of recurrent matrix: Perceptage of non-zero connections in W matrix\n",
    "    proba_non_zero_connec_Win = 1. # Sparsity of input matrix\n",
    "    proba_non_zero_connec_Wfb = 1.\n",
    "                        ### Generating random weight matrices with custom method\n",
    "    W = np.random.rand(N,N) - 0.5\n",
    "    if input_bias:\n",
    "        Win = np.random.rand(N,dim_inp+1) - 0.5\n",
    "    else:\n",
    "        Win = np.random.rand(N,dim_inp) - 0.5\n",
    "    Wfb = np.random.rand(N,n_outputs) - 0.5\n",
    "    mask = np.random.rand(N,N) # create a mask Uniform[0;1]\n",
    "    W[mask > proba_non_zero_connec_W] = 0 # set to zero some connections given by the mask\n",
    "    mask = np.random.rand(N,Win.shape[1])\n",
    "    Win[mask > proba_non_zero_connec_Win] = 0\n",
    "    Win = Win * input_scaling\n",
    "    original_spectral_radius = np.max(np.abs(np.linalg.eigvals(W)))\n",
    "    W = W * (spectral_radius / original_spectral_radius)\n",
    "    reservoir = ESN.ESN(lr=L, W=W, Win=Win, input_bias=input_bias, ridge=R, Wfb=None, fbfunc=None)\n",
    "    internal_trained = reservoir.train(inputs=[train_in], teachers=[train_out], wash_nr_time_step=initLen, verbose=False)\n",
    "    output_pred, internal_pred = reservoir.run(inputs=[valid_in,], reset_state=False)\n",
    "    df_pred = pd.DataFrame(output_pred[0])\n",
    "    df_test_out = pd.DataFrame(valid_out)\n",
    "    X_MSE = np.mean((df_test_out[0][:] - df_pred[0])**2)\n",
    "    Y_MSE = np.mean((df_test_out[1][:] - df_pred[1])**2)\n",
    "    Z_MSE = np.mean((df_test_out[2][:] - df_pred[2])**2)\n",
    "#     print('For ', N,L,R,s_r, 'parameters:: ', 'X, Y, Z MSE = ', X_MSE, Y_MSE, Z_MSE)\n",
    "#     print('RMSE = ', np.sqrt(X_MSE**2+Y_MSE**2+Z_MSE**2))\n",
    "    RMSE = np.sqrt(X_MSE**2+Y_MSE**2+Z_MSE**2)\n",
    "    parameters.append({'n_reservoir':N,'leaky_rate':L,'regularization_coef':R,'spectral_radius' :s_r})\n",
    "    Best_Parameters.append([parameters, RMSE, X_MSE])\n",
    "    df = pd.DataFrame(Best_Parameters)\n",
    "    return df.iloc[np.argmin(np.array(df[1]))][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_parameters = ESN_TUNE(n_reservoir= [300,400,500],\n",
    "         leak_rate = [ 0.3,0.2,0.1], \n",
    "         regularization_coef = [1e-3,1e-2,1e-1],\n",
    "         spectral_radius = [1,1.2,1.4,1.5], \n",
    "         n_inputs =3,\n",
    "         n_outputs = 3, \n",
    "         initLen  = initLen, \n",
    "         train_in = train_in, \n",
    "         train_out = train_out, \n",
    "         valid_in = valid_in, \n",
    "         valid_out = valid_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Parameters :', best_parameters)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
